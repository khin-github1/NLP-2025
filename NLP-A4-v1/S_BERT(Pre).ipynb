{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V27cvYbXmE3"
      },
      "source": [
        "# [Sentence-BERT](https://arxiv.org/pdf/1908.10084.pdf)\n",
        "\n",
        "[Reference Code](https://www.pinecone.io/learn/series/nlp/train-sentence-transformers-softmax/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Oiik6VsmXmE9",
        "outputId": "dd22f706-4d89-4c0a-ca42-b2c48447f432"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import math\n",
        "import re\n",
        "from   random import *\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mlrQfe-XmFA"
      },
      "source": [
        "## 1. Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QGKck2PXmFA"
      },
      "source": [
        "### Train, Test, Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PK4iS02tXmFB",
        "outputId": "832a721e-68a7-4ae0-aac0-310ee489ad6c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\AIT_lecture\\NLP\\pythonNLP\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'premise': Value(dtype='string', id=None),\n",
              " 'hypothesis': Value(dtype='string', id=None),\n",
              " 'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None),\n",
              " 'idx': Value(dtype='int32', id=None)}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load the MNLI dataset\n",
        "import datasets\n",
        "\n",
        "mnli = datasets.load_dataset('glue', 'mnli')\n",
        "mnli['train'].features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SavX_2teXmFB",
        "outputId": "9b62ec99-af50-41db-f1ab-f47c3be38d12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['train', 'validation_matched', 'validation_mismatched', 'test_matched', 'test_mismatched'])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# List of datasets to remove 'idx' column from\n",
        "mnli.column_names.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_V8EfQiiXmFC"
      },
      "outputs": [],
      "source": [
        "# Remove 'idx' column from each dataset\n",
        "for column_names in mnli.column_names.keys():\n",
        "    mnli[column_names] = mnli[column_names].remove_columns('idx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IRNV8dAIXmFD",
        "outputId": "fa06c309-02e7-4525-a06e-cb1a85821ee8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['train', 'validation_matched', 'validation_mismatched', 'test_matched', 'test_mismatched'])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mnli.column_names.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_6cI-EKmXmFD",
        "outputId": "1376bb95-6248-41ee-9080-7f6d28774140"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# list all label that have in the dataset\n",
        "import numpy as np\n",
        "np.unique(mnli['train']['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yatAFE5xXmFF",
        "outputId": "9cdaab09-b2d9-45d5-ddd6-67aef8efedce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['premise', 'hypothesis', 'label'],\n",
              "        num_rows: 10000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['premise', 'hypothesis', 'label'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['premise', 'hypothesis', 'label'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create dataset dictionary with sample data (since my computer cannot run all dataset)\n",
        "from datasets import DatasetDict\n",
        "\n",
        "raw_dataset = DatasetDict({\n",
        "    'train': mnli['train'].shuffle(seed=55).select(list(range(10000))),\n",
        "    'test': mnli['test_mismatched'].shuffle(seed=55).select(list(range(1000))),\n",
        "    'validation': mnli['validation_mismatched'].shuffle(seed=55).select(list(range(1000)))\n",
        "})\n",
        "\n",
        "raw_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b6ZWaFxXmFF"
      },
      "source": [
        "## 2. Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CTRKfbTXXmFG"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CGvL8eQdXmFG",
        "outputId": "70a82bf0-bdb3-4887-9199-b639d3e4058f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 10000/10000 [00:04<00:00, 2234.01 examples/s]\n",
            "Map: 100%|██████████| 1000/1000 [00:00<00:00, 2118.86 examples/s]\n",
            "Map: 100%|██████████| 1000/1000 [00:00<00:00, 2146.42 examples/s]\n"
          ]
        }
      ],
      "source": [
        "def preprocess_function(examples):\n",
        "    max_seq_length = 128\n",
        "    padding = 'max_length'\n",
        "    # Tokenize the premise\n",
        "    premise_result = tokenizer(\n",
        "        examples['premise'], padding=padding, max_length=max_seq_length, truncation=True)\n",
        "    #num_rows, max_seq_length\n",
        "    # Tokenize the hypothesis\n",
        "    hypothesis_result = tokenizer(\n",
        "        examples['hypothesis'], padding=padding, max_length=max_seq_length, truncation=True)\n",
        "    #num_rows, max_seq_length\n",
        "    # Extract labels\n",
        "    labels = examples[\"label\"]\n",
        "    #num_rows\n",
        "    return {\n",
        "        \"premise_input_ids\": premise_result[\"input_ids\"],\n",
        "        \"premise_attention_mask\": premise_result[\"attention_mask\"],\n",
        "        \"hypothesis_input_ids\": hypothesis_result[\"input_ids\"],\n",
        "        \"hypothesis_attention_mask\": hypothesis_result[\"attention_mask\"],\n",
        "        \"labels\" : labels\n",
        "    }\n",
        "\n",
        "tokenized_datasets = raw_dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        ")\n",
        "\n",
        "tokenized_datasets = tokenized_datasets.remove_columns(['premise','hypothesis','label'])\n",
        "tokenized_datasets.set_format(\"torch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8iPIyhfpXmFH",
        "outputId": "d72c7bb2-faf1-41a3-ad97-a03a2401cddd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n",
              "        num_rows: 10000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SM5C7-uXmFH"
      },
      "source": [
        "## 3. Data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YARzqyWiXmFH"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# initialize the dataloader\n",
        "batch_size = 32\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_datasets['train'],\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    tokenized_datasets['validation'],\n",
        "    batch_size=batch_size\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    tokenized_datasets['test'],\n",
        "    batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "p-QZ0HZYXmFH",
        "outputId": "5e52cff3-4c67-4d5c-e094-0b9ab05d1a0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 128])\n",
            "torch.Size([32, 128])\n",
            "torch.Size([32, 128])\n",
            "torch.Size([32, 128])\n",
            "torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "for batch in train_dataloader:\n",
        "    print(batch['premise_input_ids'].shape)\n",
        "    print(batch['premise_attention_mask'].shape)\n",
        "    print(batch['hypothesis_input_ids'].shape)\n",
        "    print(batch['hypothesis_attention_mask'].shape)\n",
        "    print(batch['labels'].shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-izKiYdjXmFH"
      },
      "source": [
        "## 4. Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "4c8565e0c9e849b18763197b706cbb08",
            "501e5dad29f44013abc38495fdaa4b03"
          ]
        },
        "id": "WJmBeuqJXmFI",
        "outputId": "7ec92365-6d02-4287-d030-d23b8079eae5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSdpaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# start from a pretrained bert-base-uncased model\n",
        "from transformers import BertTokenizer, BertModel\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pCbMBxZXmFI"
      },
      "source": [
        "### Pooling\n",
        "SBERT adds a pooling operation to the output of BERT / RoBERTa to derive a fixed sized sentence embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aCoAFxv8XmFI"
      },
      "outputs": [],
      "source": [
        "# define mean pooling function\n",
        "def mean_pool(token_embeds, attention_mask):\n",
        "    # reshape attention_mask to cover 768-dimension embeddings\n",
        "    in_mask = attention_mask.unsqueeze(-1).expand(\n",
        "        token_embeds.size()\n",
        "    ).float()\n",
        "    # perform mean-pooling but exclude padding tokens (specified by in_mask)\n",
        "    pool = torch.sum(token_embeds * in_mask, 1) / torch.clamp(\n",
        "        in_mask.sum(1), min=1e-9\n",
        "    )\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STCkBB-FXmFI"
      },
      "source": [
        "## 5. Loss Function\n",
        "\n",
        "## Classification Objective Function\n",
        "We concatenate the sentence embeddings $u$ and $v$ with the element-wise difference  $\\lvert u - v \\rvert $ and multiply the result with the trainable weight  $ W_t ∈  \\mathbb{R}^{3n \\times k}  $:\n",
        "\n",
        "$ o = \\text{softmax}\\left(W^T \\cdot \\left(u, v, \\lvert u - v \\rvert\\right)\\right) $\n",
        "\n",
        "where $n$ is the dimension of the sentence embeddings and k the number of labels. We optimize cross-entropy loss. This structure is depicted in Figure 1.\n",
        "\n",
        "## Regression Objective Function.\n",
        "The cosine similarity between the two sentence embeddings $u$ and $v$ is computed (Figure 2). We use means quared-error loss as the objective function.\n",
        "\n",
        "(Manhatten / Euclidean distance, semantically  similar sentences can be found.)\n",
        "\n",
        "<img src=\"./figures/sbert-architecture.png\" >"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KD-B99yNXmFI"
      },
      "outputs": [],
      "source": [
        "def configurations(u,v):\n",
        "    # build the |u-v| tensor\n",
        "    uv = torch.sub(u, v)   # batch_size,hidden_dim\n",
        "    uv_abs = torch.abs(uv) # batch_size,hidden_dim\n",
        "\n",
        "    # concatenate u, v, |u-v|\n",
        "    x = torch.cat([u, v, uv_abs], dim=-1) # batch_size, 3*hidden_dim\n",
        "    return x\n",
        "\n",
        "def cosine_similarity(u, v):\n",
        "    dot_product = np.dot(u, v)\n",
        "    norm_u = np.linalg.norm(u)\n",
        "    norm_v = np.linalg.norm(v)\n",
        "    similarity = dot_product / (norm_u * norm_v)\n",
        "    return similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftp0NbeqXmFI"
      },
      "source": [
        "<img src=\"./figures/sbert-ablation.png\" width=\"350\" height=\"300\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1oG3KM95XmFJ"
      },
      "outputs": [],
      "source": [
        "classifier_head = torch.nn.Linear(768*3, 3).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "optimizer_classifier = torch.optim.Adam(classifier_head.parameters(), lr=2e-5)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "URtwiuIXXmFK"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\AIT_lecture\\NLP\\pythonNLP\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
          ]
        }
      ],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# and setup a warmup for the first ~10% steps\n",
        "total_steps = int(len(raw_dataset) / batch_size)\n",
        "warmup_steps = int(0.1 * total_steps)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "\t\toptimizer, num_warmup_steps=warmup_steps,\n",
        "  \tnum_training_steps=total_steps - warmup_steps\n",
        ")\n",
        "\n",
        "# then during the training loop we update the scheduler per step\n",
        "scheduler.step()\n",
        "\n",
        "scheduler_classifier = get_linear_schedule_with_warmup(\n",
        "\t\toptimizer_classifier, num_warmup_steps=warmup_steps,\n",
        "  \tnum_training_steps=total_steps - warmup_steps\n",
        ")\n",
        "\n",
        "# then during the training loop we update the scheduler per step\n",
        "scheduler_classifier.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuO8a97SXmFK"
      },
      "source": [
        "## 6. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fRGn-Ie5XmFL",
        "outputId": "bf08fe27-1100-4dbc-8b45-a3133e2baa0e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/313 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [1:08:14<00:00, 13.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | loss = 1.126768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [1:11:40<00:00, 13.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2 | loss = 1.079063\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "num_epoch = 2\n",
        "best_loss = float('inf')\n",
        "# 1 epoch should be enough, increase if wanted\n",
        "for epoch in range(num_epoch):\n",
        "    model.train()\n",
        "    classifier_head.train()\n",
        "    # initialize the dataloader loop with tqdm (tqdm == progress bar)\n",
        "    for step, batch in enumerate(tqdm(train_dataloader, leave=True)):\n",
        "        # zero all gradients on each new step\n",
        "        optimizer.zero_grad()\n",
        "        optimizer_classifier.zero_grad()\n",
        "\n",
        "        # prepare batches and more all to the active device\n",
        "        inputs_ids_a = batch['premise_input_ids'].to(device)\n",
        "        inputs_ids_b = batch['hypothesis_input_ids'].to(device)\n",
        "        attention_a = batch['premise_attention_mask'].to(device)\n",
        "        attention_b = batch['hypothesis_attention_mask'].to(device)\n",
        "        label = batch['labels'].to(device)\n",
        "\n",
        "        # extract token embeddings from BERT at last_hidden_state\n",
        "        u = model(inputs_ids_a, attention_mask=attention_a)\n",
        "        v = model(inputs_ids_b, attention_mask=attention_b)\n",
        "\n",
        "        u_last_hidden_state = u.last_hidden_state # all token embeddings A = batch_size, seq_len, hidden_dim\n",
        "        v_last_hidden_state = v.last_hidden_state # all token embeddings B = batch_size, seq_len, hidden_dim\n",
        "\n",
        "         # get the mean pooled vectors\n",
        "        u_mean_pool = mean_pool(u_last_hidden_state, attention_a) # batch_size, hidden_dim\n",
        "        v_mean_pool = mean_pool(v_last_hidden_state, attention_b) # batch_size, hidden_dim\n",
        "\n",
        "        # build the |u-v| tensor\n",
        "        uv = torch.sub(u_mean_pool, v_mean_pool)   # batch_size,hidden_dim\n",
        "        uv_abs = torch.abs(uv) # batch_size,hidden_dim\n",
        "\n",
        "        # concatenate u, v, |u-v|\n",
        "        x = torch.cat([u_mean_pool, v_mean_pool, uv_abs], dim=-1) # batch_size, 3*hidden_dim\n",
        "\n",
        "        # process concatenated tensor through classifier_head\n",
        "        x = classifier_head(x) #batch_size, classifer\n",
        "\n",
        "        # calculate the 'softmax-loss' between predicted and true label\n",
        "        loss = criterion(x, label)\n",
        "        if loss < best_loss:\n",
        "            best_loss = loss\n",
        "            torch.save(model.state_dict(), 'pre_SBERT.pt')\n",
        "\n",
        "        # using loss, calculate gradients and then optimizerize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer_classifier.step()\n",
        "\n",
        "        scheduler.step() # update learning rate scheduler\n",
        "        scheduler_classifier.step()\n",
        "\n",
        "    print(f'Epoch: {epoch + 1} | loss = {loss.item():.6f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1QdSz8JUXmFL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Cosine Similarity: 0.7733\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "classifier_head.eval()\n",
        "total_similarity = 0\n",
        "with torch.no_grad():\n",
        "    for step, batch in enumerate(eval_dataloader):\n",
        "        # prepare batches and more all to the active device\n",
        "        inputs_ids_a = batch['premise_input_ids'].to(device)\n",
        "        inputs_ids_b = batch['hypothesis_input_ids'].to(device)\n",
        "        attention_a = batch['premise_attention_mask'].to(device)\n",
        "        attention_b = batch['hypothesis_attention_mask'].to(device)\n",
        "        label = batch['labels'].to(device)\n",
        "\n",
        "        # extract token embeddings from BERT at last_hidden_state\n",
        "        u = model(inputs_ids_a, attention_mask=attention_a)[0]  # all token embeddings A = batch_size, seq_len, hidden_dim\n",
        "        v = model(inputs_ids_b, attention_mask=attention_b)[0]  # all token embeddings B = batch_size, seq_len, hidden_dim\n",
        "\n",
        "        # get the mean pooled vectors\n",
        "        u_mean_pool = mean_pool(u, attention_a).detach().cpu().numpy().reshape(-1) # batch_size, hidden_dim\n",
        "        v_mean_pool = mean_pool(v, attention_b).detach().cpu().numpy().reshape(-1) # batch_size, hidden_dim\n",
        "\n",
        "        similarity_score = cosine_similarity(u_mean_pool, v_mean_pool)\n",
        "        total_similarity += similarity_score\n",
        "\n",
        "average_similarity = total_similarity / len(eval_dataloader)\n",
        "print(f\"Average Cosine Similarity: {average_similarity:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqV9h11jXmFL"
      },
      "source": [
        "## 7. Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "S5DsK0oSXmFL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine Similarity: 0.8057\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def calculate_similarity(model, tokenizer, sentence_a, sentence_b, device):\n",
        "    # Tokenize and convert sentences to input IDs and attention masks\n",
        "    inputs_a = tokenizer(sentence_a, return_tensors='pt', truncation=True, padding=True).to(device)\n",
        "    inputs_b = tokenizer(sentence_b, return_tensors='pt', truncation=True, padding=True).to(device)\n",
        "\n",
        "    # Move input IDs and attention masks to the active device\n",
        "    inputs_ids_a = inputs_a['input_ids']\n",
        "    attention_a = inputs_a['attention_mask']\n",
        "    inputs_ids_b = inputs_b['input_ids']\n",
        "    attention_b = inputs_b['attention_mask']\n",
        "\n",
        "    # Extract token embeddings from BERT\n",
        "    u = model(inputs_ids_a, attention_mask=attention_a)[0]  # all token embeddings A = batch_size, seq_len, hidden_dim\n",
        "    v = model(inputs_ids_b, attention_mask=attention_b)[0]  # all token embeddings B = batch_size, seq_len, hidden_dim\n",
        "\n",
        "    # Get the mean-pooled vectors\n",
        "    u = mean_pool(u, attention_a).detach().cpu().numpy().reshape(-1)  # batch_size, hidden_dim\n",
        "    v = mean_pool(v, attention_b).detach().cpu().numpy().reshape(-1)  # batch_size, hidden_dim\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    similarity_score = cosine_similarity(u.reshape(1, -1), v.reshape(1, -1))[0, 0]\n",
        "\n",
        "    return similarity_score\n",
        "\n",
        "# Example usage:\n",
        "sentence_a = 'Your contribution helped make it possible for us to provide our students with a quality education.'\n",
        "sentence_b = \"Your contributions were of no help with our students' education.\"\n",
        "similarity = calculate_similarity(model, tokenizer, sentence_a, sentence_b, device)\n",
        "print(f\"Cosine Similarity: {similarity:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahxZD0G-XmFL"
      },
      "source": [
        "# Predicting NLI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "AvfK_6NjXmFL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine Similarity: 0.7322\n",
            "NLI Prediction: entailment\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def predict_nli_and_similarity(model, classifier_head, tokenizer, sentence_a, sentence_b, device):\n",
        "    # Tokenize and convert sentences to input IDs and attention masks\n",
        "    inputs_a = tokenizer(sentence_a, return_tensors='pt', truncation=True, padding=True).to(device)\n",
        "    inputs_b = tokenizer(sentence_b, return_tensors='pt', truncation=True, padding=True).to(device)\n",
        "\n",
        "    # Move input IDs and attention masks to the active device\n",
        "    inputs_ids_a = inputs_a['input_ids']\n",
        "    attention_a = inputs_a['attention_mask']\n",
        "    inputs_ids_b = inputs_b['input_ids']\n",
        "    attention_b = inputs_b['attention_mask']\n",
        "\n",
        "    # Extract token embeddings from BERT\n",
        "    with torch.no_grad():\n",
        "        u = model(inputs_ids_a, attention_mask=attention_a).last_hidden_state\n",
        "        v = model(inputs_ids_b, attention_mask=attention_b).last_hidden_state\n",
        "\n",
        "    # Get the mean-pooled vectors\n",
        "    u = mean_pool(u, attention_a)\n",
        "    v = mean_pool(v, attention_b)\n",
        "\n",
        "    # Convert to numpy for cosine similarity\n",
        "    u_np = u.cpu().numpy().reshape(-1)\n",
        "    v_np = v.cpu().numpy().reshape(-1)\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    similarity_score = cosine_similarity(u_np.reshape(1, -1), v_np.reshape(1, -1))[0, 0]\n",
        "\n",
        "    # Compute NLI classification\n",
        "    uv_abs = torch.abs(u - v)  # |u - v|\n",
        "    x = torch.cat([u, v, uv_abs], dim=-1)  # Concatenate for classification\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = classifier_head(x)  # Pass through classification head\n",
        "        probabilities = F.softmax(logits, dim=-1)\n",
        "\n",
        "    # NLI labels: contradiction (0), neutral (1), entailment (2)\n",
        "    labels = [\"contradiction\", \"neutral\", \"entailment\"]\n",
        "    nli_result = labels[torch.argmax(probabilities).item()]\n",
        "\n",
        "    return similarity_score, nli_result\n",
        "\n",
        "# Example usage:\n",
        "sentence_a = \"A man is playing a guitar.\"\n",
        "sentence_b = \"A person is performing music.\"\n",
        "similarity, nli_result = predict_nli_and_similarity(model, classifier_head, tokenizer, sentence_a, sentence_b, device)\n",
        "\n",
        "print(f\"Cosine Similarity: {similarity:.4f}\")\n",
        "print(f\"NLI Prediction: {nli_result}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine Similarity: 0.7256\n",
            "NLI Prediction: neutral\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "sentence_a = \"Gays and lesbians.\"\n",
        "sentence_b = \"Heterosexuals.\"\n",
        "similarity, nli_result = predict_nli_and_similarity(model, classifier_head, tokenizer, sentence_a, sentence_b, device)\n",
        "\n",
        "print(f\"Cosine Similarity: {similarity:.4f}\")\n",
        "print(f\"NLI Prediction: {nli_result}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage:\n",
        "sentence_a = \"Gays and lesbians.\"\n",
        "sentence_b = \"Heterosexuals.\"\n",
        "similarity, nli_result = predict_nli_and_similarity(model, classifier_head, tokenizer, sentence_a, sentence_b, device)\n",
        "\n",
        "print(f\"Cosine Similarity: {similarity:.4f}\")\n",
        "print(f\"NLI Prediction: {nli_result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine Similarity: 0.6674\n",
            "NLI Prediction: entailment\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "sentence_a = \"The man should have died instantly.\"\n",
        "sentence_b = \"The man was perfectly fine.\"\n",
        "similarity, nli_result = predict_nli_and_similarity(model, classifier_head, tokenizer, sentence_a, sentence_b, device)\n",
        "\n",
        "print(f\"Cosine Similarity: {similarity:.4f}\")\n",
        "print(f\"NLI Prediction: {nli_result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pythonNLP",
      "language": "python",
      "name": "pythonnlp"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
